{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Scraping articles_WEO.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZB4seoSoHuC",
        "outputId": "6e359f27-ac47-4636-cabe-8a196d14b295"
      },
      "source": [
        "!pip install pygooglenews\n",
        "!pip install newspaper3k"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pygooglenews\n",
            "  Downloading https://files.pythonhosted.org/packages/59/cb/84f162888a07e501630f6be7c70997c5c8afd5ba4a40c3a079c321e97c29/pygooglenews-0.1.2-py3-none-any.whl\n",
            "Collecting requests<3.0.0,>=2.24.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/c1/24814557f1d22c56d50280771a17307e6bf87b70727d975fd6b2ce6b014a/requests-2.25.1-py2.py3-none-any.whl (61kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 2.3MB/s \n",
            "\u001b[?25hCollecting dateparser<0.8.0,>=0.7.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c1/d5/5a2e51bc0058f66b54669735f739d27afc3eb453ab00520623c7ab168e22/dateparser-0.7.6-py2.py3-none-any.whl (362kB)\n",
            "\u001b[K     |████████████████████████████████| 368kB 4.5MB/s \n",
            "\u001b[?25hCollecting feedparser<6.0.0,>=5.2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/d8/7d37fec71ff7c9dbcdd80d2b48bcdd86d6af502156fc93846fb0102cb2c4/feedparser-5.2.1.tar.bz2 (192kB)\n",
            "\u001b[K     |████████████████████████████████| 194kB 5.8MB/s \n",
            "\u001b[?25hCollecting beautifulsoup4<5.0.0,>=4.9.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/41/e6495bd7d3781cee623ce23ea6ac73282a373088fcd0ddc809a047b18eae/beautifulsoup4-4.9.3-py3-none-any.whl (115kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 5.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->pygooglenews) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->pygooglenews) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->pygooglenews) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->pygooglenews) (3.0.4)\n",
            "Requirement already satisfied: regex!=2019.02.19 in /usr/local/lib/python3.7/dist-packages (from dateparser<0.8.0,>=0.7.6->pygooglenews) (2019.12.20)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from dateparser<0.8.0,>=0.7.6->pygooglenews) (2.8.1)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.7/dist-packages (from dateparser<0.8.0,>=0.7.6->pygooglenews) (1.5.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from dateparser<0.8.0,>=0.7.6->pygooglenews) (2018.9)\n",
            "Collecting soupsieve>1.2; python_version >= \"3.0\"\n",
            "  Downloading https://files.pythonhosted.org/packages/36/69/d82d04022f02733bf9a72bc3b96332d360c0c5307096d76f6bb7489f7e57/soupsieve-2.2.1-py3-none-any.whl\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil->dateparser<0.8.0,>=0.7.6->pygooglenews) (1.15.0)\n",
            "Building wheels for collected packages: feedparser\n",
            "  Building wheel for feedparser (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for feedparser: filename=feedparser-5.2.1-cp37-none-any.whl size=44940 sha256=7f3ef238aa075bfe527d81aa91359252cfd716ea47beebc2cd848ce4c0993fc2\n",
            "  Stored in directory: /root/.cache/pip/wheels/8c/69/b7/f52763c41c5471df57703a0ef718a32a5e81ee35dcf6d4f97f\n",
            "Successfully built feedparser\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.25.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: requests, dateparser, feedparser, soupsieve, beautifulsoup4, pygooglenews\n",
            "  Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed beautifulsoup4-4.9.3 dateparser-0.7.6 feedparser-5.2.1 pygooglenews-0.1.2 requests-2.25.1 soupsieve-2.2.1\n",
            "Collecting newspaper3k\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/b9/51afecb35bb61b188a4b44868001de348a0e8134b4dfa00ffc191567c4b9/newspaper3k-0.2.8-py3-none-any.whl (211kB)\n",
            "\u001b[K     |████████████████████████████████| 215kB 4.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (4.9.3)\n",
            "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (2.25.1)\n",
            "Requirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (4.2.6)\n",
            "Requirement already satisfied: Pillow>=3.3.0 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (7.1.2)\n",
            "Requirement already satisfied: nltk>=3.2.1 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (2.8.1)\n",
            "Collecting tinysegmenter==0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/17/82/86982e4b6d16e4febc79c2a1d68ee3b707e8a020c5d2bc4af8052d0f136a/tinysegmenter-0.3.tar.gz\n",
            "Collecting cssselect>=0.9.2\n",
            "  Downloading https://files.pythonhosted.org/packages/3b/d4/3b5c17f00cce85b9a1e6f91096e1cc8e8ede2e1be8e96b87ce1ed09e92c5/cssselect-1.1.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: feedparser>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (5.2.1)\n",
            "Collecting feedfinder2>=0.0.4\n",
            "  Downloading https://files.pythonhosted.org/packages/35/82/1251fefec3bb4b03fd966c7e7f7a41c9fc2bb00d823a34c13f847fd61406/feedfinder2-0.0.4.tar.gz\n",
            "Requirement already satisfied: PyYAML>=3.11 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (3.13)\n",
            "Collecting tldextract>=2.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/62/b6acd3129c5615b9860e670df07fd55b76175b63e6b7f68282c7cad38e9e/tldextract-3.1.0-py2.py3-none-any.whl (87kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 6.5MB/s \n",
            "\u001b[?25hCollecting jieba3k>=0.35.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/cb/2c8332bcdc14d33b0bedd18ae0a4981a069c3513e445120da3c3f23a8aaa/jieba3k-0.35.1.zip (7.4MB)\n",
            "\u001b[K     |████████████████████████████████| 7.4MB 14.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: soupsieve>1.2; python_version >= \"3.0\" in /usr/local/lib/python3.7/dist-packages (from beautifulsoup4>=4.4.1->newspaper3k) (2.2.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->newspaper3k) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->newspaper3k) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->newspaper3k) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->newspaper3k) (2020.12.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk>=3.2.1->newspaper3k) (1.15.0)\n",
            "Collecting requests-file>=1.4\n",
            "  Downloading https://files.pythonhosted.org/packages/77/86/cdb5e8eaed90796aa83a6d9f75cfbd37af553c47a291cd47bc410ef9bdb2/requests_file-1.5.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from tldextract>=2.0.1->newspaper3k) (3.0.12)\n",
            "Building wheels for collected packages: tinysegmenter, feedfinder2, jieba3k\n",
            "  Building wheel for tinysegmenter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tinysegmenter: filename=tinysegmenter-0.3-cp37-none-any.whl size=13538 sha256=e41ff70bc43105504d24a2bb49d9409a19b6e0131c497fb9610aaca1fcd7c263\n",
            "  Stored in directory: /root/.cache/pip/wheels/81/2b/43/a02ede72324dd40cdd7ca53aad718c7710628e91b8b0dc0f02\n",
            "  Building wheel for feedfinder2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for feedfinder2: filename=feedfinder2-0.0.4-cp37-none-any.whl size=3358 sha256=5edfc3bdf459b6df5b9c8e225f283fe8635f606b5cd1634b66b4875ecaa8bc52\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/03/ca/778e3a7a627e3d98836cc890e7cb40c7575424cfd3340f40ed\n",
            "  Building wheel for jieba3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jieba3k: filename=jieba3k-0.35.1-cp37-none-any.whl size=7398406 sha256=3534e94bb2c1a054a81d126a1ca6b8f423a2dfd7d6fa5ea696eb376ac0442b99\n",
            "  Stored in directory: /root/.cache/pip/wheels/83/15/9c/a3f1f67e7f7181170ad37d32e503c35da20627c013f438ed34\n",
            "Successfully built tinysegmenter feedfinder2 jieba3k\n",
            "Installing collected packages: tinysegmenter, cssselect, feedfinder2, requests-file, tldextract, jieba3k, newspaper3k\n",
            "Successfully installed cssselect-1.1.0 feedfinder2-0.0.4 jieba3k-0.35.1 newspaper3k-0.2.8 requests-file-1.5.1 tinysegmenter-0.3 tldextract-3.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MPabPeSn0Iq"
      },
      "source": [
        "# importing required libraries\n",
        "from pygooglenews import GoogleNews\n",
        "from newspaper import Article\n",
        "import pandas as pd"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWNtjJT-n_Gw"
      },
      "source": [
        "# inputs to google news\n",
        "\n",
        "# These are the details about flood in indonesia corresponding to the Glide id of FL-2021-000030-IDN\n",
        "language = 'en'\n",
        "country = 'Kenya'\n",
        "\n",
        "search_terms = 'Flood Kenya'\n",
        "start_date = '2016-10-29'\n",
        "end_date = '2021-05-15'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8geK45IoS4n"
      },
      "source": [
        "gn = GoogleNews(lang = language, country = country)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAy4zZnLoe7n"
      },
      "source": [
        "# function to get the article content and other details from article url\n",
        "def get_article_content(article_url):\n",
        "    # get the date of posting the article\n",
        "    try:\n",
        "        news_article = Article(article_url,language='en')\n",
        "        news_article.download()\n",
        "        news_article.parse()\n",
        "        news_article.nlp()\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    # get the author\n",
        "    #print(news_article.authors)\n",
        "\n",
        "    # get the publish date\n",
        "    #print(news_article.publish_date)\n",
        "\n",
        "    #get top image\n",
        "    #print(news_article.top_image)\n",
        "\n",
        "    #get a summary of article\n",
        "    #print(news_article.summary)\n",
        "\n",
        "    # get article keywords\n",
        "    #print(news_article.keywords)\n",
        "\n",
        "    #get the article text\n",
        "    return news_article.text,news_article.top_image,news_article.keywords"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poQaCiKOoidn"
      },
      "source": [
        "# function to get top 50 new links\n",
        "def get_news_links(search_terms,start_date,end_date,event_id):\n",
        "    article_num =[]\n",
        "    article_title = []\n",
        "    article_link = []\n",
        "    article_content = []\n",
        "    publishing_date = []\n",
        "    article_image = []\n",
        "    article_keywords =[]\n",
        "    article_relevance = []\n",
        "    search = gn.search(query=search_terms, helper = True, when = None, from_ = start_date, to_ = end_date , proxies=None, scraping_bee=None)\n",
        "    count = 0\n",
        "    for item in search['entries']:\n",
        "        print(count)\n",
        "        article_num.append(count)\n",
        "        count += 1\n",
        "        article_title.append(item['title'])\n",
        "        article_link.append(item['link'])\n",
        "        article_content.append(get_article_content(item['link'])[0])\n",
        "        publishing_date.append(item['published'])\n",
        "        article_image.append(get_article_content(item['link'])[1])\n",
        "        article_keywords.append(get_article_content(item['link'])[2])\n",
        "        \n",
        "    event_id_list = [event_id]*count\n",
        "    article_relevance_list = [' ']*count\n",
        "    articles_dict = {'ID': article_num,'event_id': event_id_list,'article_title':article_title,'article_link':article_link,'article_content':article_content,'publishing_date':publishing_date,'article_image':article_image,'article_keywords':article_keywords,'article_relevance':article_relevance_list}\n",
        "    print(len(article_num))\n",
        "    print(len(article_title))\n",
        "    print(len(article_link))\n",
        "    print(len(article_content))\n",
        "    print(len(publishing_date))\n",
        "    print(len(article_image))\n",
        "    print(len(article_keywords))\n",
        "    print(len(article_relevance))\n",
        "    df = pd.DataFrame(articles_dict)\n",
        "    #news_results_list = zip(article_num,article_title,article_link,article_content,publishing_date,article_image,article_keywords,article_relevance)\n",
        "    return df"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EwFmWuNVoodv",
        "outputId": "5753ff3e-ee65-4f10-be34-37294c81e8e9"
      },
      "source": [
        "# searching for disaster events in news articles\n",
        "# event_id is the glide id for which we are scraping the news_articles\n",
        "news_results_list = get_news_links(search_terms,start_date,end_date,'http://floodlist.com/africa/kenya-floods-may-2021')\n",
        " # to be taken from the historical dataset\n",
        "\n",
        "news_results_list"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/dateutil/parser/_parser.py:1218: UnknownTimezoneWarning: tzname MST identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
            "  category=UnknownTimezoneWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "100\n",
            "100\n",
            "100\n",
            "100\n",
            "100\n",
            "100\n",
            "0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>event_id</th>\n",
              "      <th>article_title</th>\n",
              "      <th>article_link</th>\n",
              "      <th>article_content</th>\n",
              "      <th>publishing_date</th>\n",
              "      <th>article_image</th>\n",
              "      <th>article_keywords</th>\n",
              "      <th>article_relevance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>http://floodlist.com/africa/kenya-floods-may-2021</td>\n",
              "      <td>Kenya: Floods - Emergency Plan of Action (EPoA...</td>\n",
              "      <td>https://reliefweb.int/report/kenya/kenya-flood...</td>\n",
              "      <td>A. Situation analysis\\n\\nDescription of the di...</td>\n",
              "      <td>Tue, 27 Apr 2021 07:00:00 GMT</td>\n",
              "      <td>https://reliefweb.int/sites/reliefweb.int/file...</td>\n",
              "      <td>[n, mdrke047, rift, parts, rainfall, country, ...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>http://floodlist.com/africa/kenya-floods-may-2021</td>\n",
              "      <td>Kenya: Floods - Final Report Appeal n° MDRKE04...</td>\n",
              "      <td>https://reliefweb.int/report/kenya/kenya-flood...</td>\n",
              "      <td>A. SITUATION ANALYSIS\\n\\nDescription of the di...</td>\n",
              "      <td>Fri, 30 Apr 2021 07:00:00 GMT</td>\n",
              "      <td>https://reliefweb.int/sites/reliefweb.int/file...</td>\n",
              "      <td>[n, rains, rainfall, parts, country, appeal, r...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>http://floodlist.com/africa/kenya-floods-may-2021</td>\n",
              "      <td>How Kenya Copes with Thousands of Displaced Cl...</td>\n",
              "      <td>https://time.com/5953402/climate-migrants-keny...</td>\n",
              "      <td>When he was a child, James Owuor loved hearing...</td>\n",
              "      <td>Thu, 22 Apr 2021 07:00:00 GMT</td>\n",
              "      <td>https://api.time.com/wp-content/uploads/2021/0...</td>\n",
              "      <td>[lake, change, m, displaced, adaptation, thous...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>http://floodlist.com/africa/kenya-floods-may-2021</td>\n",
              "      <td>Kenya's climate resilience under strain amid r...</td>\n",
              "      <td>http://www.xinhuanet.com/english/africa/2021-0...</td>\n",
              "      <td>Source: Xinhua| 2021-05-14 20:48:12|Editor: hu...</td>\n",
              "      <td>Fri, 14 May 2021 12:48:12 GMT</td>\n",
              "      <td></td>\n",
              "      <td>[past, green, local, realize, parts, kenyas, f...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>http://floodlist.com/africa/kenya-floods-may-2021</td>\n",
              "      <td>Floods, traffic mess as heavy rains pound Nair...</td>\n",
              "      <td>https://nairobinews.nation.co.ke/editors-picks...</td>\n",
              "      <td>A man jumps over a flooded section of Universi...</td>\n",
              "      <td>Mon, 10 May 2021 07:00:00 GMT</td>\n",
              "      <td>https://nairobinews.nation.co.ke/wp-content/up...</td>\n",
              "      <td>[road, nairobi, mess, heavy, flooded, way, cit...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>95</td>\n",
              "      <td>http://floodlist.com/africa/kenya-floods-may-2021</td>\n",
              "      <td>2020 Rewind: Five Major Disasters That Wreaked...</td>\n",
              "      <td>https://weather.com/en-IN/india/news/news/2020...</td>\n",
              "      <td>Cyclone Amphan induces high, rough tides at Ka...</td>\n",
              "      <td>Thu, 31 Dec 2020 08:00:00 GMT</td>\n",
              "      <td>https://s.w-x.co/in-locust_swarm_0.jpg</td>\n",
              "      <td>[worldwide, disasters, million, lakh, rewind, ...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>96</td>\n",
              "      <td>http://floodlist.com/africa/kenya-floods-may-2021</td>\n",
              "      <td>Global Weather Hazards Summary: December 04-10...</td>\n",
              "      <td>https://reliefweb.int/report/world/global-weat...</td>\n",
              "      <td>A poor start to the rainy season has resulted ...</td>\n",
              "      <td>Sat, 05 Dec 2020 08:00:00 GMT</td>\n",
              "      <td>https://reliefweb.int/sites/reliefweb.int/file...</td>\n",
              "      <td>[start, rainfall, weather, summary, parts, hig...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>97</td>\n",
              "      <td>http://floodlist.com/africa/kenya-floods-may-2021</td>\n",
              "      <td>Kenya: Floods - Emergency Plan of Action, DREF...</td>\n",
              "      <td>https://reliefweb.int/report/kenya/kenya-flood...</td>\n",
              "      <td>Situation analysis\\n\\nDescription of the disas...</td>\n",
              "      <td>Tue, 29 Oct 2019 07:00:00 GMT</td>\n",
              "      <td>https://reliefweb.int/sites/reliefweb.int/file...</td>\n",
              "      <td>[iod, n, rainfall, positive, heavy, parts, dre...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>98</td>\n",
              "      <td>http://floodlist.com/africa/kenya-floods-may-2021</td>\n",
              "      <td>New Wave of Locust, Severe Floods Threaten Eas...</td>\n",
              "      <td>https://weather.com/news/news/2020-05-06-locus...</td>\n",
              "      <td>A man attempts to fend-off a swarm of desert l...</td>\n",
              "      <td>Wed, 06 May 2020 07:00:00 GMT</td>\n",
              "      <td>https://s.w-x.co/2020-02-27T131202Z_1264416841...</td>\n",
              "      <td>[africas, locust, swarm, food, threaten, flood...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>99</td>\n",
              "      <td>http://floodlist.com/africa/kenya-floods-may-2021</td>\n",
              "      <td>Kenya Flash Update No. 3: Floods | 27 November...</td>\n",
              "      <td>https://reliefweb.int/report/kenya/kenya-flash...</td>\n",
              "      <td>HIGHLIGHTS\\n\\n• More than 160,000 people, incl...</td>\n",
              "      <td>Wed, 27 Nov 2019 08:00:00 GMT</td>\n",
              "      <td>https://reliefweb.int/sites/reliefweb.int/file...</td>\n",
              "      <td>[2019, 27, update, affected, river, counties, ...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    ID  ... article_relevance\n",
              "0    0  ...                  \n",
              "1    1  ...                  \n",
              "2    2  ...                  \n",
              "3    3  ...                  \n",
              "4    4  ...                  \n",
              "..  ..  ...               ...\n",
              "95  95  ...                  \n",
              "96  96  ...                  \n",
              "97  97  ...                  \n",
              "98  98  ...                  \n",
              "99  99  ...                  \n",
              "\n",
              "[100 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQNDiS6OopXo"
      },
      "source": [
        "news_results_list.to_csv('data_flood_Kenya_Africa.csv',index=False)"
      ],
      "execution_count": 11,
      "outputs": []
    }
  ]
}