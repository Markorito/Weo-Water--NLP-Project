{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text preprocessing colab",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__LB3OZ6wsN2"
      },
      "source": [
        "## Text pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULbg3oqACFvm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be4d699e-8e55-4c07-f7be-c4526c5b1b14"
      },
      "source": [
        "# Loading libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "import io\n",
        "from io import BytesIO\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from google.colab import files"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9B47NbhqCt6x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "outputId": "0eabcde9-d13f-4e73-955c-1f671dde0d4d"
      },
      "source": [
        "path = '/content/drive/MyDrive/Preprocessed_tweets_data_twint.csv'\n",
        "df = pd.read_csv(path)\n",
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>date/time range</th>\n",
              "      <th>timezone</th>\n",
              "      <th>user_id</th>\n",
              "      <th>username</th>\n",
              "      <th>place</th>\n",
              "      <th>tweet</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>Cleaned Tweets</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2020-10-31 07:56:37</td>\n",
              "      <td>800</td>\n",
              "      <td>17580230</td>\n",
              "      <td>jarallen</td>\n",
              "      <td>Not Specified</td>\n",
              "      <td>@austinperroux @NWSSanAntonio Same here. I’ve ...</td>\n",
              "      <td>NoTags</td>\n",
              "      <td>['austinperroux', 'NWSSanAntonio', 'I’ve', 'ne...</td>\n",
              "      <td>flood</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2020-10-31 07:49:35</td>\n",
              "      <td>800</td>\n",
              "      <td>472122299</td>\n",
              "      <td>philippinestar</td>\n",
              "      <td>Not Specified</td>\n",
              "      <td>Flooding (including flash floods), rain-induce...</td>\n",
              "      <td>NoTags</td>\n",
              "      <td>['Flooding', 'including', 'flash', 'floods', '...</td>\n",
              "      <td>flood</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2020-10-31 07:23:57</td>\n",
              "      <td>800</td>\n",
              "      <td>2453732882</td>\n",
              "      <td>ttweathercenter</td>\n",
              "      <td>Not Specified</td>\n",
              "      <td>7:20 PM - Flash flooding continues in Arouca t...</td>\n",
              "      <td>NoTags</td>\n",
              "      <td>['720', 'PM', 'Flash', 'flooding', 'continues'...</td>\n",
              "      <td>flood</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2020-10-31 07:12:06</td>\n",
              "      <td>800</td>\n",
              "      <td>2453732882</td>\n",
              "      <td>ttweathercenter</td>\n",
              "      <td>Not Specified</td>\n",
              "      <td>Another video of the flash flooding ongoing at...</td>\n",
              "      <td>NoTags</td>\n",
              "      <td>['Another', 'video', 'flash', 'flooding', 'ong...</td>\n",
              "      <td>flood</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2020-10-31 07:10:16</td>\n",
              "      <td>800</td>\n",
              "      <td>2453732882</td>\n",
              "      <td>ttweathercenter</td>\n",
              "      <td>Not Specified</td>\n",
              "      <td>7:05 PM - Flash flooding ongoing at Henry Stre...</td>\n",
              "      <td>NoTags</td>\n",
              "      <td>['705', 'PM', 'Flash', 'flooding', 'ongoing', ...</td>\n",
              "      <td>flood</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...  category\n",
              "0           0  ...     flood\n",
              "1           1  ...     flood\n",
              "2           2  ...     flood\n",
              "3           3  ...     flood\n",
              "4           4  ...     flood\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jy4yghvKGN2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "250bd20d-4836-475b-f33f-80697bb73511"
      },
      "source": [
        "#Code to display all details in the columns\n",
        "pd.set_option('display.max_columns', None)  \n",
        "pd.set_option('display.expand_frame_repr', False)\n",
        "pd.set_option('max_colwidth', -1)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3xeAP45Z5Xb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50adc91a-5399-4a34-b806-abab23847232"
      },
      "source": [
        "# Converting emojis and emoticons to words\n",
        "!pip install emot\n",
        "from emot.emo_unicode import UNICODE_EMO, EMOTICONS\n",
        "# Converting emojis to words\n",
        "import re\n",
        "def convert_emojis(text):\n",
        "    for emot in UNICODE_EMO:\n",
        "        text = text.replace(emot, \"_\".join(UNICODE_EMO[emot].replace(\",\",\"\").replace(\":\",\"\").split()))\n",
        "        return text\n",
        "# Converting emoticons to words    \n",
        "def convert_emoticons(text):\n",
        "    for emot in EMOTICONS:\n",
        "        text = re.sub(u'('+emot+')', \"_\".join(EMOTICONS[emot].replace(\",\",\"\").split()), text)\n",
        "        return text\n",
        "# Passing both functions to 'text_rare'\n",
        "df['tweet'] = df['tweet'].apply(convert_emoticons)\n",
        "df['tweet'] = df['tweet'].apply(convert_emojis)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting emot\n",
            "  Downloading https://files.pythonhosted.org/packages/49/07/20001ade19873de611b7b66a4d5e5aabbf190d65abea337d5deeaa2bc3de/emot-2.1-py3-none-any.whl\n",
            "Installing collected packages: emot\n",
            "Successfully installed emot-2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUY5fwy2mLHK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60fa8a3c-557c-4599-a798-9b9eae19561a"
      },
      "source": [
        "import nltk\n",
        "from nltk.tokenize import RegexpTokenizer # For tokenization\n",
        "from nltk.stem import WordNetLemmatizer,PorterStemmer # For lemmatization\n",
        "from nltk.corpus import stopwords# To remove stop words\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "import re\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stemmer = PorterStemmer() \n",
        "\n",
        "def preprocess(sentence):\n",
        "    sentence=str(sentence)\n",
        "    sentence = sentence.lower()\n",
        "    sentence=sentence.replace('{html}',\"\") # removing html files\n",
        "    cleanr = re.compile('<.*?>') # Removing punctuation\n",
        "    cleantext = re.sub(cleanr, '', sentence)\n",
        "    rem_url=re.sub(r'http\\S+', '',cleantext) # Removing links\n",
        "    rem_num = re.sub('[0-9]+', '', rem_url)  # Removing numbers\n",
        "    tokenizer = RegexpTokenizer(r'\\w+') # Tokenization\n",
        "    tokens = tokenizer.tokenize(rem_num)  \n",
        "    filtered_words = [w for w in tokens if len(w) > 2 if not w in stopwords.words('english')]\n",
        "    stem_words=[stemmer.stem(w) for w in filtered_words]\n",
        "    lemma_words=[lemmatizer.lemmatize(w) for w in stem_words]\n",
        "    return \" \".join(filtered_words)\n",
        "\n",
        "# Mapping our loop to our datasets\n",
        "df['tweet']=df['tweet'].map(lambda s:preprocess(s))\n",
        "df['tweet']=df['tweet'].map(lambda s:preprocess(s))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KREfZt38r18y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "246882de-fc0d-49e2-d511-b468cecb65de"
      },
      "source": [
        "# Spelling correction\n",
        "!pip install textblob\n",
        "# Spell check using text blob for the first 5 records\n",
        "from textblob import TextBlob\n",
        "df['tweet'][:5].apply(lambda x: str(TextBlob(x).correct()))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: textblob in /usr/local/lib/python3.7/dist-packages (0.15.3)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.7/dist-packages (from textblob) (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob) (1.15.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    austinperroux nwssanantonio never seen water rise glad river creeks flash flood extent ever present danger along corridor never forget events                                \n",
              "1    flooding including flash floods rain induced landslide sediment laden streamflows later may occur heavy prolonged rainfall especially areas highly highly susceptible hazards\n",
              "2    flash flooding continues around tonight time avoid entering flood waters                                                                                                     \n",
              "3    another video flash flooding going henry street around time thunderstorm affects area avoid entering flood waters                                                            \n",
              "4    flash flooding going henry street around time avoid entering flood waters                                                                                                    \n",
              "Name: tweet, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jqzPozsYWyA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "618e8417-5556-4d57-b08b-4a867a9f11f5"
      },
      "source": [
        "# Common word removal\n",
        "# Checking the first 10 most frequent words\n",
        "from collections import Counter\n",
        "cnt = Counter()\n",
        "for text in df[\"tweet\"].values:\n",
        "    for word in text.split():\n",
        "        cnt[word] += 1\n",
        "        \n",
        "cnt.most_common(10)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('flood', 13148),\n",
              " ('flash', 3722),\n",
              " ('floods', 3664),\n",
              " ('flooding', 3620),\n",
              " ('flooded', 3248),\n",
              " ('amp', 3117),\n",
              " ('inundating', 3096),\n",
              " ('inundation', 3048),\n",
              " ('inundated', 3012),\n",
              " ('disaster', 2461)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    }
  ]
}